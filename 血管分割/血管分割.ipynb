{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":65343,"databundleVersionId":7185748,"sourceType":"competition"},{"sourceId":3544116,"sourceType":"datasetVersion","datasetId":2131323},{"sourceId":6081576,"sourceType":"datasetVersion","datasetId":3481724},{"sourceId":7130119,"sourceType":"datasetVersion","datasetId":4113640}],"dockerImageVersionId":30512,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:03:51.242131Z","iopub.execute_input":"2023-12-06T02:03:51.242923Z","iopub.status.idle":"2023-12-06T02:04:07.936192Z","shell.execute_reply.started":"2023-12-06T02:03:51.242882Z","shell.execute_reply":"2023-12-06T02:04:07.935078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#加载一些基础的库\nimport torch\nimport numpy as np\nimport os\nimport torchvision\nfrom tqdm import tqdm #一个实现进度条的库\nimport random\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom PIL import Image\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:04:07.938553Z","iopub.execute_input":"2023-12-06T02:04:07.939011Z","iopub.status.idle":"2023-12-06T02:04:11.515638Z","shell.execute_reply.started":"2023-12-06T02:04:07.938974Z","shell.execute_reply":"2023-12-06T02:04:11.514659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Brightness:\n    def __init__(self,brightness_factor):\n        self.brightness_factor=brightness_factor\n    def __call__(self, img):\n        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # 通过cv2.cvtColor把图像从BGR转换到HSV\n        darker_hsv = img_hsv.copy()\n        darker_hsv[:, :, 2] =  self.brightness_factor * darker_hsv[:, :, 2]\n        return cv2.cvtColor(darker_hsv, cv2.COLOR_HSV2BGR)   \n\ndef image_deal(ori_img):\n#     filename = f'/kaggle/input/2dtest/train/train/image/A-{number}.png'\n#     imgs = cv2.imread(filename)\n    brightness=Brightness(1.2)\n    imgs2=brightness(ori_img)\n    return imgs2","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:04:11.516911Z","iopub.execute_input":"2023-12-06T02:04:11.517553Z","iopub.status.idle":"2023-12-06T02:04:11.525469Z","shell.execute_reply.started":"2023-12-06T02:04:11.517517Z","shell.execute_reply":"2023-12-06T02:04:11.524476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\ni=cv2.imread('/kaggle/input/newsegment/segmentation -plus/train/image/6.jpg')\no=Image.open('/kaggle/input/newsegment/segmentation -plus/train/label/6.jpg')\nprint(type(i))\nprint(type(o))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:04:11.527648Z","iopub.execute_input":"2023-12-06T02:04:11.527908Z","iopub.status.idle":"2023-12-06T02:04:11.621787Z","shell.execute_reply.started":"2023-12-06T02:04:11.527885Z","shell.execute_reply":"2023-12-06T02:04:11.620834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 图像增强\ntransform1 = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((256,256))\n])\n\n#首先继承Dataset写一个对于数据进行读入和处理的方式\nclass MyDataset(Dataset):\n    def __init__(self,path):\n        self.mode=('train' if 'label' in os.listdir(path) else 'test')#表示训练模式\n        self.path=path#图片路径\n        dirlist=os.listdir(path+'image/')#图片的名称\n        self.name=[n for n in dirlist if n[-3:]=='jpg'] #只读取图片\n        \n    def __len__(self):\n        return len(self.name)\n    \n    def __getitem__(self,index):#获取数据的处理方式\n        name=self.name[index]\n        #读取原始图片和标签\n        if self.mode=='train':#训练模式\n          #  print(self.path + 'image/' + name)\n           # print(self.path + 'label/' + name)\n            ori_img = cv2.imread(self.path + 'image/' + name)  # 原始图片\n            l_img = Image.open(self.path + 'label/' + name)  # 标签图片\n            lb_img=np.array(l_img)\n            #ori_img= image_deal(ori_img)\n            #print(type(ori_img))\n            #print(type(lb_img))\n            ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)  # 转为RGB三通道图\n            lb_img = cv2.cvtColor(lb_img, cv2.COLOR_BGR2RGB)  # 掩膜转为灰度图\n            lb_img = cv2.cvtColor(lb_img, cv2.COLOR_RGB2GRAY) \n            ori_img = transform1(ori_img)\n            lb_img = transform1(lb_img)\n            return ori_img, lb_img\n\n        \n        if self.mode=='test':#测试模式\n            ori_img=cv2.imread(self.path+'image/'+name)#原始图片\n            ori_img=cv2.cvtColor(ori_img,cv2.COLOR_BGR2RGB)#转为RGB三通道图\n            return transform1(ori_img)\n\n#加载数据集\ntrain_path='/kaggle/input/lovenever/segmentation -plus/train/'\ntraindata=MyDataset(train_path)\nclass MyDataset_deal(Dataset):\n    def __init__(self,path):\n        self.mode=('train' if 'label' in os.listdir(path) else 'test')#表示训练模式\n        self.path=path#图片路径\n        dirlist=os.listdir(path+'image/')#图片的名称\n        self.name=[n for n in dirlist if n[-3:]=='jpg'] #只读取图片\n        \n    def transform2(self,ori_img,seed):\n        torch.manual_seed(seed),\n        transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.RandomRotation(50),  # 随机旋转\n        transforms.RandomCrop((256, 512)) ,  # 随机裁剪\n        transforms.RandomHorizontalFlip(),  # 随机水平翻转\n        transforms.Resize((256, 256))\n        ])\n        return transform(ori_img)\n\n    def __len__(self):\n        return len(self.name)\n    \n    def __getitem__(self,index):#获取数据的处理方式\n        name=self.name[index]\n        seed=np.random.randint(0,5200)\n        #读取原始图片和标签\n        if self.mode=='train':#训练模式\n            #print(self.path + 'image/' + name)\n            ori_img = cv2.imread(self.path + 'image/' + name)  # 原始图片\n            l_img = Image.open(self.path + 'label/' + name)  # 标签图片\n            lb_img=np.array(l_img)\n            #print(type(ori_img))\n            #print(self.path + 'label/' + name)\n            #print(type(lb_img))\n            #ori_img= image_deal(ori_img)\n            ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)  # 转为RGB三通道图\n            lb_img = cv2.cvtColor(lb_img, cv2.COLOR_BGR2RGB)  # 掩膜转为灰度图\n            lb_img = cv2.cvtColor(lb_img, cv2.COLOR_RGB2GRAY)\n            ori_img = self.transform2(ori_img,seed)\n            lb_img = self.transform2(lb_img,seed)\n            return ori_img, lb_img\n\n#加载数据集\ntrain_path='/kaggle/input/lovenever/segmentation -plus/train/'\ntraindata_deal=MyDataset_deal(train_path)\nfrom torch.utils.data import ConcatDataset\ntraindata = ConcatDataset([traindata, traindata_deal])","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:04:11.623288Z","iopub.execute_input":"2023-12-06T02:04:11.623831Z","iopub.status.idle":"2023-12-06T02:04:11.661676Z","shell.execute_reply.started":"2023-12-06T02:04:11.623794Z","shell.execute_reply":"2023-12-06T02:04:11.660787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\n# number = random.choice(range(4000))\n#查看图片读取效果\nimport matplotlib.pyplot as plt\nnumber=np.random.randint(1,20)\n# print(type(number))\n# print(type(np.random.randint(0,4000))\n# print(number)\no_img,l_img=traindata[number]\nplt.subplot(1,2,1)\nplt.imshow(o_img.permute(1,2, 0))\nplt.subplot(1,2,2)\nplt.imshow(l_img.permute(1,2, 0))\nplt.imshow(o_img[0], cmap='gray')  # 显示原始图像（单通道）\nplt.subplot(1, 2, 2)\nplt.imshow(l_img[0], cmap='gray')  # 显示标签图像（单通道）\nprint(\"原始图片张量的形状:\",o_img.shape)\nprint(\"标签图片张量的形状:\",l_img.shape)#([1, 320, 640]) 其中 1 表示分类类别，我们为2分类任务,类别表示为01","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:04:11.662868Z","iopub.execute_input":"2023-12-06T02:04:11.663202Z","iopub.status.idle":"2023-12-06T02:04:12.259673Z","shell.execute_reply.started":"2023-12-06T02:04:11.663173Z","shell.execute_reply":"2023-12-06T02:04:12.258817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport torch.nn as nn\nimport segmentation_models_pytorch as smp\n'''\n加载经典用于医学图像分割的UNet,encoder_name为模型的backbone\nencoder_weigths可选imagenet或者None代表是否加载预训练参数\nin_channel为输入图像的通道数\nclasses为分类数目\n'''\nmodel = smp.UnetPlusPlus(\n        encoder_name=\"resnet50\",  \n        encoder_weights=None,\n        in_channels=3,\n        classes=1,\n    )\n##打印模型信息\n#print(model) ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:04:12.320178Z","iopub.execute_input":"2023-12-06T02:04:12.320507Z","iopub.status.idle":"2023-12-06T02:04:15.474138Z","shell.execute_reply.started":"2023-12-06T02:04:12.320482Z","shell.execute_reply":"2023-12-06T02:04:15.473063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#配置模型超参数\n#模型保存的路径\nmodel_path='/kaggle/working/'\n#推荐使用gpu进行训练\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#学习率\nlr=3e-5\n#学习率衰减\nweight_decay=1e-3\n#批大小\nbs=4\n#训练轮次\nepochs=100","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:12:08.781220Z","iopub.execute_input":"2023-12-06T02:12:08.782141Z","iopub.status.idle":"2023-12-06T02:12:08.787283Z","shell.execute_reply.started":"2023-12-06T02:12:08.782097Z","shell.execute_reply":"2023-12-06T02:12:08.786276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#训练前准备\nfrom torch.utils.data import DataLoader\n#加载模型到gpu或cpu\nmodel.to(device)\n#使用Binary CrossEntropy作为损失函数，主要处理二分类问题\n# BCEloss=nn.BCELoss()\n#加载优化器,使用Adam,主要是炼的快(๑ت๑)\noptim=torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n#使用traindata创建dataloader对象\ntrainloader=DataLoader(traindata,batch_size=bs, shuffle=True, num_workers=1)\n#根据赛题评测选用dice_loss，这个是开源代码\ndef dice_loss(logits, target):\n    smooth = 1.\n    prob  = torch.sigmoid(logits)\n    batch = prob.size(0)\n    prob   = prob.view(batch,1,-1)\n    target = target.view(batch,1,-1)\n    intersection = torch.sum(prob*target, dim=2)\n    denominator  = torch.sum(prob, dim=2) + torch.sum(target, dim=2)\n    dice = (2*intersection + smooth) / (denominator + smooth)\n    dice = torch.mean(dice)\n    dice_loss = 1. - dice\n    return dice_loss","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:12:11.083605Z","iopub.execute_input":"2023-12-06T02:12:11.084390Z","iopub.status.idle":"2023-12-06T02:12:11.103686Z","shell.execute_reply.started":"2023-12-06T02:12:11.084357Z","shell.execute_reply":"2023-12-06T02:12:11.102791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#开始炼丹 没有做验证集，各位可以以自己需要去添加\nloss_last=99999\nbest_model_name=''\n#记录loss变化\nfor epoch in range(1,epochs+1):\n    for step,(inputs,labels) in tqdm(enumerate(trainloader),desc=f\"Epoch {epoch}/{epochs}\",\n                                       ascii=True, total=len(trainloader)):\n        #原始图片和标签\n        inputs, labels = inputs.to(device), labels.to(device)\n        out = model(inputs)\n        loss = dice_loss(out, labels)\n        # 后向\n        optim.zero_grad()\n        #梯度反向传播\n        loss.backward()\n        optim.step()\n    #损失小于上一轮则添加\n    if loss<loss_last:\n        loss_last=loss\n        torch.save(model.state_dict(),model_path+'model_epoch{}_loss{}.pth'.format(epoch,loss))\n        best_model_name=model_path+'model_epoch{}_loss{}.pth'.format(epoch,loss)\n    print(f\"\\nEpoch: {epoch}/{epochs},DiceLoss:{loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:25:32.692167Z","iopub.execute_input":"2023-12-06T02:25:32.692567Z","iopub.status.idle":"2023-12-06T02:31:00.647669Z","shell.execute_reply.started":"2023-12-06T02:25:32.692537Z","shell.execute_reply":"2023-12-06T02:31:00.646585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#加载最优模型\nmodel.load_state_dict(torch.load(best_model_name))\n#加载测试集\ntest_path='/kaggle/input/lovenever/segmentation -plus/test/'\ntestdata=MyDataset(test_path)\n#测试模型的预测效果\nx=np.random.randint(0,40)\ninputs=testdata[x].to(device)\nwith torch.no_grad():\n    # 模型预测\n    t = model(inputs.view(1,3,256,256))\nplt.subplot(1,2,1)\nplt.imshow(testdata[x].permute(1,2,0))\n#对预测的图片采取一定的阈值进行分类\nthreshold=0.5\nt= torch.where(t >=threshold, torch.tensor(255,dtype=torch.float).to(device), t)\nt= torch.where(t < threshold, torch.tensor(0,dtype=torch.float).to(device), t)\nt=t.cpu().view(1,256,256)\nplt.subplot(1,2,2)\nplt.imshow(t.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:31:30.856682Z","iopub.execute_input":"2023-12-06T02:31:30.857385Z","iopub.status.idle":"2023-12-06T02:31:31.452243Z","shell.execute_reply.started":"2023-12-06T02:31:30.857353Z","shell.execute_reply":"2023-12-06T02:31:31.451307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir output","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:06:08.000334Z","iopub.execute_input":"2023-12-06T02:06:08.000610Z","iopub.status.idle":"2023-12-06T02:06:09.004831Z","shell.execute_reply.started":"2023-12-06T02:06:08.000580Z","shell.execute_reply":"2023-12-06T02:06:09.003485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import save_image\nfrom PIL import Image\n\nimg_save_path='/kaggle/working/output/'\nfor i,inputs in tqdm(enumerate(testdata)):\n    #原始图片和标签\n    inputs=inputs.reshape(1,3,256,256).to(device)\n    # 输出生成的图像\n    out = model(inputs.view(1,3,256,256)) # 模型预测\n    #对输出的图像进行后处理\n    threshold=0.5\n    out= torch.where(out >=threshold, torch.tensor(255,dtype=torch.float).to(device),out)\n    out= torch.where(out < threshold, torch.tensor(0,dtype=torch.float).to(device),out)\n    #保存图像\n    out= out.detach().cpu().numpy().reshape(1,256,256)\n    #注意保存为1位图提交\n    img = Image.fromarray(out[0].astype(np.uint8))\n    img = img.convert('1')\n    img.save(img_save_path + testdata.name[i])","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:31:37.264418Z","iopub.execute_input":"2023-12-06T02:31:37.265318Z","iopub.status.idle":"2023-12-06T02:31:38.662754Z","shell.execute_reply.started":"2023-12-06T02:31:37.265284Z","shell.execute_reply":"2023-12-06T02:31:38.661761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#对保存的图像进行打包\nimport zipfile\n\ndef zip_files(file_paths, output_path):\n    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for file in file_paths:\n            zipf.write(file)\n            \n#打包图片\nfile_paths = [img_save_path+i for i in os.listdir(img_save_path) if i[-3:]=='jpg']\noutput_path = '/kaggle/working/output.zip'\nzip_files(file_paths, output_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:06:10.670969Z","iopub.execute_input":"2023-12-06T02:06:10.671277Z","iopub.status.idle":"2023-12-06T02:06:10.703586Z","shell.execute_reply.started":"2023-12-06T02:06:10.671250Z","shell.execute_reply":"2023-12-06T02:06:10.702750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torchvision\nimport os\n\"\"\"\nIn order to reduce the submission file size, our metric uses run-length encoding on the pixel values.\nInstead of submitting an exhaustive list of indices for your segmentation, you will submit pairs of values \nthat contain a start position and a run length.\nE.g. '1 3' implies starting at pixel 1 and running a total of 3 pixels 1,2,3. The competition format requires a space\ndelimited list of pairs. For example, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask. \nThe metric checks that the pairs are sorted, positive, and the decoded pixel values are not duplicated. \nThe pixels are numbered from top to bottom, then left to right: 1 is pixel 1,1, 2 is pixel 2,1, etc. \nThe file should contain a header and have the following format: > > img,pixels > 1,1 1 5 1 > 2,1 1 > 3,1 1 > etc.\n\"\"\"\n\ndef get_img_file(image_dir):\n    imagelist = []\n    namelist = []\n    for parent, dirnames, filenames in os.walk(image_dir):\n        for filename in filenames:\n            if filename.lower().endswith(\n                    ('.bmp', '.dib', '.png', '.jpg', '.jpeg', '.pbm', '.pgm', '.ppm', '.tif', '.gif')):\n                imagelist.append(os.path.join(parent, filename))\n                namelist.append(filename)\n        return imagelist, namelist\n\n\ndef turn_to_str(image_list):\n    outputs = []\n    for image_path in image_list:\n        image = Image.open(image_path).convert('L')\n        transform = torchvision.transforms.ToTensor()\n        image = image.resize((512, 512), Image.Resampling.BILINEAR)\n        image = transform(image)\n        image[image > 0] = 1\n        dots = np.where(image.flatten() == 1)[0]\n        run_lengths = []\n        prev = -2\n        for b in dots:\n            if (b > prev + 1):\n                run_lengths.extend((b + 1, 0))\n            run_lengths[-1] += 1\n            prev = b\n        output = ' '.join([str(r) for r in run_lengths])\n        outputs.append(output)\n    return outputs\n\n\ndef save_to_csv(name_list, str_list):\n    df = pd.DataFrame(columns=['Id', 'Predicted'])\n    #df['Id'] = [i.split('.')[0] for i in name_list]\n    df['Id'] = [int(i.replace(\".jpg\", \"\")) for i in name_list]\n    df['Id'] = name_list\n    df['Predicted'] = str_list\n    df.head(3)\n    df.to_csv('sample_submission.csv', index=None)\n\n\nif __name__==\"__main__\":\n    image_dir = '/kaggle/working/output'\n    image_list, name_list = get_img_file(image_dir)\n    str_list = turn_to_str(image_list)\n    #name_list = [i for i in range(1,21)]\n    #str_list = [\"\" for i in range(20)]\n    #save_to_csv(name_list, str_list)\n    df = pd.DataFrame(columns=['Id', 'Predicted'])\n    df['Id'] = [i.split('.')[0] for i in name_list]\n    \n    #df['Id'] = name_list\n    df['Predicted'] = str_list\n    df.head(3)\n    df.to_csv('sample_submission.csv', index=None)\n    print(df)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:31:48.414307Z","iopub.execute_input":"2023-12-06T02:31:48.414676Z","iopub.status.idle":"2023-12-06T02:31:50.949962Z","shell.execute_reply.started":"2023-12-06T02:31:48.414648Z","shell.execute_reply":"2023-12-06T02:31:50.948945Z"},"trusted":true},"execution_count":null,"outputs":[]}]}